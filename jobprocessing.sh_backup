#!/bin/bash

AWS_COMMAND=$(which aws)
if [ ! -f ${AWS_COMMAND} ]; then
  echo "ERROR: Missing aws commands, install awscli"
  exit 2
fi

if ! $(python -c "import boto.sqs" &> /dev/null); then
   echo "ERROR: boto libary for aws services not installed in python" >&2
   exit 2
fi

YOUR_AWS_REGION="us-east-1"

####################################################
# Create an S3 Bucket to host input and output files
# You can create a bucket from the [S3 web console](http://console.aws.amazon.com/s3/) or using the CLI:
S3_BUCKET_NAME="ec2jobprocessing01"      ##<S3 Bucket Name> ## Make all lower case letters  ## <Your AWS Region, e.g. "eu-west-1">
 aws s3 mb s3://${S3_BUCKET_NAME} \
   --region ${YOUR_AWS_REGION}
  if [ $? -ne 0 ]; then
    echo "FAIL: create bucket"
  fi

#####################################################
# Create an SQS Queue to centralize "job" requests
SQS_QUEUE_NAME="batch-queue"  ## <SQS Queue Name>
  aws sqs create-queue \
    --queue-name ${SQS_QUEUE_NAME} \
    --region ${YOUR_AWS_REGION} \


# ####################################################
# ## Create a IAM Role to delegate access to processing instances

# # NOTE: THIS NEEDS TO BE DONE FROM AWS web console
# From the [IAM web console](http://console.aws.amazon.com/iam/) -> Roles -> Create Role -> 
# Write a role name.Under "AWS Service Roles" select "Amazon EC2".
# Select a "Custom Policy", write a policy name and see the "role.json" file
# for a sample role giving access to an S3 bucket and an SQS queue.
# You should replace "AWS Account", "S3 Bucket Name" and "SQS Queue Name" in the policy with yours.
# Write down the Instance Profile ARN from the Summary tab, you'll need it later.

INSTANCE_PROFILE_ARN="arn:aws:iam::022996467674:instance-profile/ec2jobprocessingrole"

#####################################################
### Create Auto Scaling Launch Configuration
LAUNCH_CONFIGURATION_NAME="asl-batch" 
LINUX_AMI_ID=ami-0b898040803850657 ## These are region specific
INSTANCE_TYPE=t2.micro   ## The instance profile to launch EC2 Instance Type, e.g. t1.micro
SSH_KEY=ec2jobprocessing ## <EC2 Key Pair for SSH login>

  aws autoscaling create-launch-configuration \
    --launch-configuration-name ${LAUNCH_CONFIGURATION_NAME} \
    --image-id ${LINUX_AMI_ID} \
    --instance-type ${INSTANCE_TYPE} \
    --iam-instance-profile ${INSTANCE_PROFILE_ARN} \
    --region ${YOUR_AWS_REGION} \
    --key-name ${SSH_KEY} \
    --user-data "`cat user-data.sh`"

#####################################################
### Create Auto Scaling Group
AUTO_SCALING_GROUP_NAME="asg-batch" ## 
MAX_NUM_INSTANCES_TO_START=1 ## <Max Number of Instances to start when there are "jobs" in the SQS queue>

## NOTE: You must restrict your AZ's to those available in your VPC
AZ_IN_YOUR_DEFAULT_VPC="us-east-1a us-east-1b us-east-1c" ## All AZs in the region,
# ##  e.g. for "eu-west-1" you can use "eu-west-1a" "eu-west-1b" "eu-west-1c"
  aws autoscaling create-auto-scaling-group \
    --auto-scaling-group-name ${AUTO_SCALING_GROUP_NAME} \
    --launch-configuration-name ${LAUNCH_CONFIGURATION_NAME} \
    --min-size 0 \
    --max-size ${MAX_NUM_INSTANCES_TO_START} \
    --availability-zones ${AZ_IN_YOUR_DEFAULT_VPC} \
    --region ${YOUR_AWS_REGION} \
    --default-cooldown 300

#####################################################
### Create Auto Scaling "Up" Policy
AUTO_SCALE_UP_POLICY_NAME="ash-batch-upscale-policy"
NUM_JOBS_TO_UPSCALE=1
  aws autoscaling put-scaling-policy \
    --region ${YOUR_AWS_REGION} \
    --auto-scaling-group-name ${AUTO_SCALING_GROUP_NAME} \
    --policy-name ${AUTO_SCALE_UP_POLICY_NAME} \
    --scaling-adjustment ${NUM_JOBS_TO_UPSCALE} \
    --adjustment-type ExactCapacity |tee UP_POLICY_ARN.log 2>&1

# HACK TO GET the policy from script
UP_POLICY_ARN=$(cat UP_POLICY_ARN.log |grep PolicyARN| awk -F\" '{print $4'})
#Write down the "PolicyARN", you need it in the next step to set up the alarm.

## Create CloudWatch Alarm to trigger "Up" scaling Policy
  aws cloudwatch put-metric-alarm \
    --region ${YOUR_AWS_REGION} \
    --alarm-name StartBatchProcessing \
    --metric-name ApproximateNumberOfMessagesVisible \
    --namespace "AWS/SQS" \
    --statistic Average \
    --period 60  \
    --evaluation-periods 2 \
    --threshold 1 \
    --comparison-operator GreaterThanOrEqualToThreshold \
    --dimensions Name=QueueName,Value=batch-queue \
    --alarm-actions ${UP_POLICY_ARN}


## Create Auto Scaling "Down" Policy
AUTO_SCALE_DOWN_POLICY_NAME="ash-batch-downscale-policy"
  aws autoscaling put-scaling-policy \
  	--region ${YOUR_AWS_REGION} \
    --auto-scaling-group-name ${AUTO_SCALING_GROUP_NAME} \
    --policy-name ${AUTO_SCALE_DOWN_POLICY_NAME} \
    --scaling-adjustment 0 \
    --adjustment-type ExactCapacity |tee DOWN_POLICY_ARN.log 2>&1

DOWN_POLICY_ARN=$(cat DOWN_POLICY_ARN.log |grep PolicyARN| awk -F\" '{print $4'})
#Write down the "PolicyARN", you need it in the next step to set up the alarm.

## Create CloudWatch Alarm to trigger "Down" scaling Policy
  aws cloudwatch put-metric-alarm \
  	--region ${YOUR_AWS_REGION} \
    --alarm-name StopBatchProcessing \
    --metric-name ApproximateNumberOfMessagesVisible \
    --namespace "AWS/SQS" \
    --statistic Average \
    --period 60  \
    --evaluation-periods 2 \
    --threshold 0 \
    --comparison-operator LessThanOrEqualToThreshold \
    --dimensions Name=QueueName,Value=batch-queue \
    --alarm-actions ${DOWN_POLICY_ARN}
